# app.py â€” Streamlit ë¦¬ë·° ì˜ˆì¸¡(íšŒê·€ ì „ìš©)
# -*- coding: utf-8 -*-

from __future__ import annotations
import re
from pathlib import Path

import joblib
import numpy as np
import pandas as pd
import streamlit as st

# =========================
# ê¸°ë³¸ ì„¤ì •
# =========================
st.set_page_config(page_title="ë¦¬ë·° ì˜ˆì¸¡/ë¶„ì„", page_icon="â­", layout="wide")

ROOT = Path(__file__).resolve().parent
MODELS = ROOT / "models"

VEC_PKL = MODELS / "tfidf_vectorizer.pkl"
REG_JOBLIB = MODELS / "rf_reg.joblib"

def _assert_files_exist(paths):
    miss = [p for p in paths if not p.exists()]
    if miss:
        st.error(f"ëª¨ë¸ íŒŒì¼ ëˆ„ë½: {[str(p) for p in miss]}")
        st.stop()

# =========================
# ì „ì²˜ë¦¬/í† í¬ë‚˜ì´ì¦ˆ
# =========================
POS_EMO = "ğŸ˜€ğŸ˜ƒğŸ˜„ğŸ˜ğŸ˜†ğŸ™‚ğŸ˜ŠğŸ˜ğŸ¤©ğŸ˜‹ğŸ˜‰ğŸ‘ğŸ™ŒğŸ‰â¤ğŸ’–ğŸ’—ğŸ’“ğŸ’ğŸ’•âœ¨ğŸ˜»ğŸ¥°ğŸ¤—ğŸ˜ºğŸ˜¸"
NEG_EMO = "ğŸ˜ğŸ˜ŸğŸ˜ ğŸ˜¡ğŸ˜¢ğŸ˜­ğŸ¤®ğŸ˜’ğŸ˜•ğŸ™â˜¹ğŸ‘ğŸ’¢ğŸ˜£ğŸ˜–ğŸ¤¬ğŸ˜¤ğŸ’”ğŸ˜¿ğŸ˜¹"
URL_RE = re.compile(r"(https?:\/\/[^\s]+)")
HTML_RE = re.compile(r"<[^>]+>")
MULTI_SPACE = re.compile(r"\s+")

def _replace_emojis(text: str) -> str:
    text = re.sub(f"[{re.escape(POS_EMO)}]+", " [EMO_POS] ", text)
    text = re.sub(f"[{re.escape(NEG_EMO)}]+", " [EMO_NEG] ", text)
    text = re.sub(r"[\U00010000-\U0010ffff]", " [EMO] ", text)
    return text

def _clean_text(s: str) -> str:
    if not isinstance(s, str):
        return ""
    s = s.replace("\u200b", " ")
    s = HTML_RE.sub(" ", s)
    s = URL_RE.sub(" [URL] ", s)
    s = _replace_emojis(s)
    s = re.sub(r"[^0-9A-Za-zê°€-í£\.\,\!\?\[\]_ ]+", " ", s)
    s = MULTI_SPACE.sub(" ", s).strip()
    return s

def tokenize_and_join(s: str) -> str:
    return " ".join(re.findall(r"[ê°€-í£A-Za-z0-9]{2,}", _clean_text(s)))

# =========================
# í˜¸í™˜ íŒ¨ì¹˜ (RF)
# =========================
def _patch_rf_monotonic(reg_model):
    try:
        from sklearn.ensemble import RandomForestRegressor
        from sklearn.pipeline import Pipeline
        rf = None
        if isinstance(reg_model, Pipeline):
            last = reg_model.steps[-1][1]
            if isinstance(last, RandomForestRegressor):
                rf = last
        elif isinstance(reg_model, RandomForestRegressor):
            rf = reg_model
        if rf is not None and getattr(rf, "estimators_", None) is not None:
            for est in rf.estimators_:
                if not hasattr(est, "monotonic_cst"):
                    setattr(est, "monotonic_cst", None)
    except Exception:
        pass
    return reg_model

# =========================
# ëª¨ë¸ ë¡œë“œ (ìºì‹œ)
# =========================
@st.cache_resource(show_spinner=True)
def load_models():
    _assert_files_exist([VEC_PKL, REG_JOBLIB])
    vec = joblib.load(VEC_PKL)
    reg = joblib.load(REG_JOBLIB)
    reg = _patch_rf_monotonic(reg)
    return vec, reg

# =========================
# ìœ„í—˜ë„ íŒì •
# =========================
def risk_level(avg_score: float) -> str:
    # Safe â‰¥ 4.10, Low â‰¥ 4.00, Medium â‰¥ 3.90, High < 3.90
    if avg_score >= 4.10:
        return "Safe"
    if avg_score >= 4.00:
        return "Low"
    if avg_score >= 3.90:
        return "Medium"
    return "High"

def risk_color(level: str) -> str:
    return {
        "Safe":   "#2e7d32",
        "Low":    "#558b2f",
        "Medium": "#f9a825",
        "High":   "#c62828",
    }.get(level, "#333333")

# ==========================================================
#                          UI
# ==========================================================
st.title("â­ ë¦¬ë·° ì˜ˆì¸¡ ë°ëª¨")

vec, reg = load_models()

# â”€â”€ ë‹¨ì¼ ì˜ˆì¸¡
st.subheader("ë‹¨ì¼ í…ìŠ¤íŠ¸ ì˜ˆì¸¡")
inp = st.text_area("ë¦¬ë·° í…ìŠ¤íŠ¸ ì…ë ¥", height=160, placeholder="ë¦¬ë·°ë¥¼ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”â€¦")
if st.button("ì˜ˆì¸¡í•˜ê¸°") and inp.strip():
    toks = tokenize_and_join(inp)
    X = vec.transform([toks])
    score = float(np.clip(reg.predict(X)[0], 1, 5))  # 1~5ë¡œ í´ë¦½
    st.metric("ì˜ˆì¸¡ ì ìˆ˜", f"{score:.2f} â˜…")

st.divider()

# â”€â”€ ë°°ì¹˜ ì˜ˆì¸¡
st.subheader("ë°°ì¹˜ ì˜ˆì¸¡ (CSV ì—…ë¡œë“œ)")
csv = st.file_uploader("CSV ì—…ë¡œë“œ (í•„ìˆ˜ ì»¬ëŸ¼: review_text)", type=["csv"])

if csv is not None:
    try:
        df = pd.read_csv(csv)
    except Exception as e:
        st.error(f"CSV ë¡œë”© ì‹¤íŒ¨: {e}")
    else:
        if "review_text" not in df.columns:
            st.error("CSVì— 'review_text' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # ì˜ˆì¸¡
            toks = df["review_text"].fillna("").astype(str).map(tokenize_and_join)
            X = vec.transform(toks)
            df["pred_score"] = np.clip(reg.predict(X), 1, 5).round(2)

            # í™”ë©´ í‘œì‹œìš© ì»¬ëŸ¼ êµ¬ì„± (queryëŠ” ìˆ¨ê¹€)
            view_cols = []
            if "review_text" in df.columns:
                view_cols.append("review_text")
            if "review_date" in df.columns:
                view_cols.append("review_date")
            view_cols.append("pred_score")

            df_view = df.loc[:, view_cols].rename(
                columns={
                    "review_text": "ë¦¬ë·°",
                    "review_date": "ë‚ ì§œ",
                    "pred_score":  "ì˜ˆì¸¡ ë³„ì ",
                }
            )

            st.dataframe(df_view, use_container_width=True)

            # ===== í‰ê·  & ìœ„í—˜ë„ =====
            avg = float(df["pred_score"].mean())
            level = risk_level(avg)
            col1, col2 = st.columns([1, 1])
            with col1:
                st.metric("ë‚˜ì˜ í‰ê·  í‰ì ", f"{avg:.2f} â˜…")
            with col2:
                st.markdown(
                    f"""
                    <div style="padding:10px 12px;border-radius:10px;
                                background:{risk_color(level)};color:#fff;
                                display:inline-block;font-weight:600;">
                        ìœ„í—˜ë„: {level}
                    </div>
                    """,
                    unsafe_allow_html=True,
                )

            # ===== ë‹¤ìš´ë¡œë“œ =====
            st.download_button(
                "ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                df.to_csv(index=False, encoding="utf-8-sig"),
                file_name="predictions.csv",
                mime="text/csv",
            )
